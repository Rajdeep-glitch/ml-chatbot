{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9cJrx3pqDZLx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zxOpSurmNpWG"
   },
   "outputs": [],
   "source": [
    "model = \"tiiuae/falcon-7b-instruct\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237,
     "referenced_widgets": [
      "908d367592334286bbea8b1efda87171",
      "e52b2b5717d34b269a064672b9d9838e",
      "fd3fd82266fd4b3995f84a492e266697",
      "fc5407500ac24c07a608de9505e6a9e3",
      "02235e869c874019968b391b4d2605e1",
      "1651fccc11f04a76ace446abf6dfd5ca",
      "3c7fb039e4d54de6bb29a205a9bf3e58",
      "0a7559a9024643b2ad9ea114f459a58b",
      "e6bd94389f3441ceb525d9447e53aa59",
      "3a389bb1e15b43d9abe04f7ed4a483f2",
      "9763b0a1df9f4eeda97c3cb3775ab8d3",
      "6c5e61b49ea642669dfccb1af97e8e5c",
      "a8444ad124604a6c95e26da87bca0087",
      "b1610e78f12f48d3a8f631687627cbdf",
      "0ae504d3b7b043fc92e1f86bcb9a8aaf",
      "5ca78b457df647c3a58136c4655829c9",
      "60feab9151be472aa42ba8196f1c975c",
      "24c30e0b74f1480db8d76d8268d67d56",
      "830cdef952f743c5b66049aa17e908bd",
      "ea81f94e760b4326a718db65fa84b573",
      "a0b99a2f199d426580eec30ac28c8810",
      "f28258f5ea3c4bd88abb27dc560a7f2e",
      "cd810ff907dd42298bebfda06328ed66",
      "f69492c41a5b4a50a845cd5922bf47c9",
      "2c17b552003c4814ac05032175b71be8",
      "135a7a864d20494d9b026675baab8d84",
      "cb34cde091e94606908b4ebd6ddeb30c",
      "b3ead6868aae43359c5a591224e267d4",
      "3cc27af66e4741b6b82aaeca7b6d493b",
      "aa316989fe894b9198ed223c24244838",
      "b2cc1d20ece94b4dadda06e0fb31bff9",
      "d2a530eb073243238ff2c938cd75f74f",
      "9a7a144b4bfa4522881e07acb0644c35"
     ]
    },
    "id": "-5QZIOwHNyel",
    "outputId": "c3887708-45d0-472e-caf3-d4972d748ee1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908d367592334286bbea8b1efda87171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5e61b49ea642669dfccb1af97e8e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd810ff907dd42298bebfda06328ed66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499,
     "referenced_widgets": [
      "8497cd3be56c420ebb6e59fe2e8b76a1",
      "89f151fb214b46b7929bbb28fd1bb50f",
      "50618a1ed54b4925938070f4182399cb",
      "5db97f32a80545d38c7716f287b5915f",
      "95f59bcd80c2434f87cc98ec12dfd279",
      "95f9762fd6b04a62a48783570ac38b4b",
      "94e39bdca78f4b28a58da6357b272168",
      "6f7c7980dd2245ea9bd64dabe31440ce",
      "25b528d6761b43da9e655ba3282d0b37",
      "ced92c9af8b64464a2846714cae83a84",
      "62177ff4f4474557a3caab62e4dfe7b1",
      "684bd14031f64e19b7b188a5f543f04b",
      "fd259aea357344129d28033be4003084",
      "e0fd6600cca944d396c452740eb1149e",
      "2cff448c2e25436a88d653f7cba44640",
      "a72f71054baf4356b7cb2c419eedb650",
      "d6c83678dd464a21811c9af2cb87a249",
      "f197138c28c04c2fb28822987008e77a",
      "3bdc7829b36d46508714948c9204dfc9",
      "5a8216f089ed491dbb6916473e06c391",
      "54018d6ec5274f038621318f515c506e",
      "23f6da96334f4e32b0c53cecd409dff2",
      "8924f4a07f8a41f480927d6993427b21",
      "8cf32739781a42948ca5e8f89ff226a3",
      "aaf8cb30d689453ab465921889199adc",
      "758217a08c89433391a0d0dfe9d88a8c",
      "5bbc9a0cacc1490995285c2b4fa3d2f5",
      "9d63bb83eadd478baa20eb77ed1bec59",
      "c2462faa1221435680f278b8ebae8c40",
      "4bb9d4a7f9944430a42de4bb72ea7228",
      "74929fdbc8c540d4beab56d29e80c522",
      "b405930cfab546a3af7fdee049a946ba",
      "14512e144b084ee2b83722289f8a541f",
      "f7d026fa4abd47c486dbfabbab096ba2",
      "ac514655fc3d46b19d897237bdcf9410",
      "4e66bb9404d346ceb2feb4c34f72517a",
      "83a0a9267ac54a5abcbcf8363362810a",
      "72c44944a8f147cf96d349c195b0e723",
      "ff86d84b06a543babe7a25116367c857",
      "f7e17c32bc424055be1a4a03893d0e3e",
      "c1614b40212f461083639154ba610aef",
      "de8799b0e08d470d9d5034cc76b45a71",
      "617c08ade5734e73966e35e28931d697",
      "93d6c287fd99406487dd04d3da531e91",
      "b0a2054351fb4d84941aae2e69cd081f",
      "8d83e7c3e1b24b61aaa4b2c5bcb6a2df",
      "b5496e7d00b64fa698536f4393c76bb6",
      "bbe896615c8e44e08ccdf4b9739de34d",
      "78ca897ffc484fe28c551d436a551fb6",
      "411ce6549bb5466ab5db4248694774c5",
      "e8890c4384e3493e816104189758175b",
      "f7fca8d703cc4354b1103d606546e809",
      "6e86cd082cf44eb9b2479fdc85dec333",
      "e8fdc105da1542de859629482310d444",
      "9f3743baba654dffbcb632b0d204e1ea",
      "3880d2a8537c4e4282325160b64260e5",
      "386e6bfcb0cb45f6b2e87a204e4fdb98",
      "6b374472e5b74c9dbb3ded7b42271ca7",
      "942c9d7ef775438da751d085aa641d3c",
      "835924ee912643d399361ed612f17e27",
      "87023a19bcbc4ccfaacd8f7c71ae3679",
      "4122accc5acc4011ad398db125600385",
      "a0bf78624f5948818dd5f3fda23e329c",
      "698f89844a6b446c812782efd1072352",
      "f44c5c7ef335425e884256008829ed0d",
      "0c03b822e5374165b3763663445a16b8",
      "bb4675685be846d79a8f5608b9c8dfd5",
      "39007af3a4cc43e1900723cb18d82e71",
      "c49bc0a5561342beb35cd52e2a0da4e5",
      "543d1bd1e47f4cf5bc584975f622a3bf",
      "eed31d52fbf54788bfff6256b5ad6f63",
      "8582035995f045eb8fc6664e9a7a72ad",
      "79a24c78adb74a95859a7cb70b9b6f8b",
      "24c778fa4b534d10aee9cb4399454848",
      "3d9d9617710a4919bdaa0e38a35130c3",
      "84d0f9e9823a4b71a5db5225800bbfae",
      "1aad881a191d4f6a8fee351815e9eeba",
      "2457f72f82c345459634a665cd654b59",
      "4eff9f30760747298525becbcf54f863",
      "286e1681025f47a49eb733f7a90c1f23",
      "f1f2d3ed1763455fb2bdecd0971d061d",
      "4c98af232c1e44bca04d2a7e9066d868",
      "f1ae4bb76e8947869534bc73141bda1c",
      "b7fae0371c3d47cfa4e210a8105dff66",
      "dc21cd7636d24a88bb25fd22fb9ab851",
      "de5177e8e6784904bcacc4ada3592f8b",
      "b138258a61d6476dab832549bad4fa88",
      "190c17407f484df4ada63ace8b34e4c2",
      "0cb659a5cfdb480caaf6a3dfaf74a103",
      "9a28ff9512ee4baeb64197a96ffdcf0b",
      "a2d7646da76a4d379ee27bd34c309ff1",
      "983e6e5c7ff64ec88705fbc1e8776994",
      "2fb03713b7a84bebb554de6e70e6441d",
      "88d1d63000bc4b65a0dfb2ce77497062",
      "031c6507e56044eba5e1ea1700cb6375",
      "47ea8f83454045ae9485503d7b0c65ea",
      "4caa15f838654e5da3f9cbe79930f559",
      "289d8a94d27049a98fa4fa1045b05ea2",
      "791946484e5444a28e51ee54a06269e4"
     ]
    },
    "id": "KRJ8rqi8N--N",
    "outputId": "d5330cd5-fc57-4e13-a2a6-fcd00db0366f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8497cd3be56c420ebb6e59fe2e8b76a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684bd14031f64e19b7b188a5f543f04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_falcon.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n",
      "- configuration_falcon.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "WARNING:transformers_modules.tiiuae.falcon-7b-instruct.8782b5c5d8c9290412416618f36a133653e85285.configuration_falcon:\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8924f4a07f8a41f480927d6993427b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_falcon.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n",
      "- modeling_falcon.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d026fa4abd47c486dbfabbab096ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a2054351fb4d84941aae2e69cd081f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3880d2a8537c4e4282325160b64260e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4675685be846d79a8f5608b9c8dfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2457f72f82c345459634a665cd654b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb659a5cfdb480caaf6a3dfaf74a103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E00hAXNzOQ1w"
   },
   "outputs": [],
   "source": [
    "prompt = \"What is relativity?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "aptFQXTDYMXb",
    "outputId": "6211b9d5-980e-42ff-c0b8-1b01aa0a9b00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> What is earth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=500) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m sure you’ve heard that the Earth is a planet. What do you think makes a planet different from any other celestial body in our solar system?\n",
      "\n",
      "> What is realtivity?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=500) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(laughs) That was a funny question. Well, let me explain. \"Realtivity\" is a word I made up to describe a relationship between two objects. It means the distance between them, or how close they are.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-6-149911141.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdialog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{my_name}: {user_input}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdialog\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"\\n{your_name}: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "newline_token = tokenizer.encode(\"\\n\")[0]\n",
    "\n",
    "my_name = \"Alice\"\n",
    "your_name = \"Bob\"\n",
    "dialog = []\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"> \")\n",
    "    dialog.append(f\"{my_name}: {user_input}\")\n",
    "    prompt = \"\\n\".join(dialog) + f\"\\n{your_name}: \"\n",
    "    sequences = pipeline(\n",
    "        prompt,\n",
    "        max_length=500,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        return_full_text=False,\n",
    "        eos_token_id=newline_token,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    print(sequences[0]['generated_text'])\n",
    "    dialog.append(\"Bob: \"+sequences[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
